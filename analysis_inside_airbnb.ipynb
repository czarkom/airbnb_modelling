{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('data/listings_inside_airbnb.csv')\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "df.head(50)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "airbnb = df.drop(columns=['id', 'name', 'listing_url','scrape_id','last_scraped', 'source', 'picture_url', 'host_id', 'host_url', 'host_name', 'host_location', 'host_response_time', 'host_acceptance_rate', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_total_listings_count', 'host_verifications', 'neighbourhood', 'neighbourhood_cleansed', 'property_type', 'minimum_nights', 'bathrooms_text', 'maximum_nights', 'maximum_minimum_nights', 'minimum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability', 'availability_30', 'availability_60', 'availability_90', 'availability_365', 'calendar_last_scraped', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'first_review', 'last_review', 'review_scores_accuracy', 'review_scores_value', 'instant_bookable', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', 'reviews_per_month', 'license'])\n",
    "print(airbnb.shape)\n",
    "airbnb"
   ],
   "id": "8797d0bae03dbfb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Data cleaning",
   "id": "e63b45c6faa0628a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "airbnb.isnull().sum()/len(airbnb)*100",
   "id": "b2e33c0bd7192494",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "missing_values = airbnb.isnull().sum()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "missing_values.plot(kind='bar', color='skyblue')\n",
    "plt.title('Number of Missing Values per Column', fontsize=16)\n",
    "plt.xlabel('Columns', fontsize=14)\n",
    "plt.ylabel('Number of Missing Values', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "deabb6bd37dc1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "airbnb = airbnb.dropna(subset=['price'])\n",
    "print(airbnb.isnull().sum()/len(airbnb)*100)\n",
    "airbnb.shape"
   ],
   "id": "57c0f6459b0b9d30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "airbnb['host_identity_verified'].value_counts()",
   "id": "40b5f4b2f1ad595d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop columns where's not much data or data is not valuable\n",
    "airbnb = airbnb.drop(columns=['neighborhood_overview', 'host_about', 'host_identity_verified'])"
   ],
   "id": "930edd2a2baf8a0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Number of duplicates before removal operation: {airbnb.duplicated().sum()}\")\n",
    "airbnb = airbnb.drop_duplicates()\n",
    "print(f\"Number of duplicates after removal operation: {airbnb.duplicated().sum()}\")"
   ],
   "id": "f93bd84a83429991",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ast\n",
    "\n",
    "# Convert price from string to number\n",
    "airbnb['price'] = airbnb['price'].str.replace('$', '', regex=False).str.replace(',', '', regex=False).str.strip().astype(float)\n",
    "\n",
    "# Convert date to number of dates\n",
    "airbnb['host_since'] = pd.to_datetime(airbnb['host_since'])\n",
    "today = pd.to_datetime('today')\n",
    "airbnb['host_since'] = (today - airbnb['host_since']).dt.days\n",
    "\n",
    "# Create a new column 'amenities_count' with the count of items in the list\n",
    "airbnb['amenities_count'] = airbnb['amenities'].apply(lambda x: len(ast.literal_eval(x)))\n",
    "airbnb = airbnb.drop(columns=['amenities'])\n",
    "\n",
    "# Convert string to number and fill empty values with mean\n",
    "airbnb['host_response_rate'] = airbnb['host_response_rate'].str.rstrip('%').astype('float') / 100\n",
    "mean = airbnb['host_response_rate'].mean()\n",
    "print(f\"Filling {airbnb['host_response_rate'].isna().sum()} values with mean {mean}\")\n",
    "airbnb['host_response_rate'] = airbnb['host_response_rate'].fillna(mean)"
   ],
   "id": "665a87ff7131ba8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "airbnb['price'].describe()",
   "id": "27359b7ccd88ffd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fill ratings with mean values\n",
    "mean = airbnb['review_scores_rating'].mean()\n",
    "print(f\"Filling {airbnb['review_scores_rating'].isna().sum()} values with mean {mean}\")\n",
    "airbnb['review_scores_rating'] = airbnb['review_scores_rating'].fillna(mean)\n",
    "\n",
    "mean = airbnb['review_scores_cleanliness'].mean()\n",
    "print(f\"Filling {airbnb['review_scores_cleanliness'].isna().sum()} values with mean {mean}\")\n",
    "airbnb['review_scores_cleanliness'] = airbnb['review_scores_cleanliness'].fillna(mean)\n",
    "\n",
    "mean = airbnb['review_scores_checkin'].mean()\n",
    "print(f\"Filling {airbnb['review_scores_checkin'].isna().sum()} values with mean {mean}\")\n",
    "airbnb['review_scores_checkin'] = airbnb['review_scores_checkin'].fillna(mean)\n",
    "\n",
    "mean = airbnb['review_scores_communication'].mean()\n",
    "print(f\"Filling {airbnb['review_scores_communication'].isna().sum()} values with mean {mean}\")\n",
    "airbnb['review_scores_communication'] = airbnb['review_scores_communication'].fillna(mean)\n",
    "\n",
    "mean = airbnb['review_scores_location'].mean()\n",
    "print(f\"Filling {airbnb['review_scores_location'].isna().sum()} values with mean {mean}\")\n",
    "airbnb['review_scores_location'] = airbnb['review_scores_location'].fillna(mean)"
   ],
   "id": "78e6dfcbf4de73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Null elements count: {airbnb.isna().sum().sum()}\")\n",
    "airbnb.shape"
   ],
   "id": "382f4d7b1973a647",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "airbnb = airbnb.dropna()\n",
    "print(f\"Null elements count: {airbnb.isna().sum().sum()}\")\n",
    "print(f\"Final shape {airbnb.shape}\")"
   ],
   "id": "c9782a26ca4859c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Feature engineering",
   "id": "7853a05a7ce58c66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distance to attractions\n",
    "nyc_attractions = [\n",
    "    {\"name\": \"Statue of Liberty\", \"latitude\": 40.6892, \"longitude\": -74.0445},\n",
    "    {\"name\": \"Central Park\", \"latitude\": 40.7851, \"longitude\": -73.9683},\n",
    "    {\"name\": \"Times Square\", \"latitude\": 40.7580, \"longitude\": -73.9855},\n",
    "    {\"name\": \"Empire State Building\", \"latitude\": 40.7484, \"longitude\": -73.9857},\n",
    "    {\"name\": \"Brooklyn Bridge\", \"latitude\": 40.7061, \"longitude\": -73.9969},\n",
    "    {\"name\": \"Metropolitan Museum of Art\", \"latitude\": 40.7794, \"longitude\": -73.9632},\n",
    "    {\"name\": \"One World Trade Center\", \"latitude\": 40.7127, \"longitude\": -74.0134},\n",
    "    {\"name\": \"Rockefeller Center\", \"latitude\": 40.7587, \"longitude\": -73.9787},\n",
    "    {\"name\": \"Broadway\", \"latitude\": 40.7590, \"longitude\": -73.9845},\n",
    "    {\"name\": \"Fifth Avenue\", \"latitude\": 40.7750, \"longitude\": -73.9650}\n",
    "]\n",
    "\n",
    "import numpy as np\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def calculate_avg_distance(row, attractions):\n",
    "    distances = []\n",
    "    for attraction in attractions:\n",
    "        dist = haversine(row['latitude'], row['longitude'], attraction['latitude'], attraction['longitude'])\n",
    "        distances.append(dist)\n",
    "    return np.mean(distances)\n",
    "\n",
    "airbnb['avg_distance_to_attractions'] = airbnb.apply(lambda row: calculate_avg_distance(row, nyc_attractions), axis=1)"
   ],
   "id": "194dac28cf654eef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sentiment anlaysis\n",
    "from textblob import TextBlob\n",
    "\n",
    "def calculate_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "airbnb['description_sentiment'] = airbnb['description'].apply(calculate_sentiment)\n",
    "airbnb['description_length'] = airbnb['description'].apply(len)\n",
    "descriptions_merged = \" \".join(airbnb['description'])\n",
    "airbnb = airbnb.drop(columns=['description'])"
   ],
   "id": "2eeab7f4067c757b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dataframe after cleaning and features engineering\n",
    "airbnb.head()"
   ],
   "id": "2526171a176facb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Columns available after features engineering\n",
    "airbnb.columns"
   ],
   "id": "784a50c42eb02ffb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Exploratory data analysis",
   "id": "d0cccff5ee301be9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "custom_stopwords = set(STOPWORDS)\n",
    "custom_stopwords.update(['br', 'New York', 'New', 'York', 'Manhattan'])  # Add more if needed\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    stopwords=custom_stopwords,\n",
    "    colormap='viridis',\n",
    "    max_words=200\n",
    ").generate(descriptions_merged)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.title(\"Word Cloud for Descriptions\", fontsize=16)\n",
    "plt.show()"
   ],
   "id": "74f8cfc028ad395e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "nyc_map = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "marker_cluster = MarkerCluster().add_to(nyc_map)\n",
    "\n",
    "for idx, row in airbnb.iterrows():\n",
    "    folium.Marker(location=[row['latitude'], row['longitude']], \n",
    "                  popup=f\"Price: ${row['price']}\\n Avg. dist. to attractions: {row['avg_distance_to_attractions']:.2f}km\\n Accommodates: {row['accommodates']}\",\n",
    "                  icon=folium.Icon(color='blue', icon='home')).add_to(marker_cluster)\n",
    "\n",
    "nyc_map.save('nyc_airbnb_map.html')\n",
    "nyc_map"
   ],
   "id": "a6a53faf251449d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "nyc_shapefile = gpd.read_file('data/geo_export_4bd92b16-3dab-4b86-80ae-a5283a9caffa.shp')\n",
    "\n",
    "neighbourhood_avg_price = airbnb.groupby('neighbourhood_group_cleansed')['price'].mean().reset_index()\n",
    "\n",
    "nyc_geo = nyc_shapefile.merge(neighbourhood_avg_price, left_on='boro_name', right_on='neighbourhood_group_cleansed')\n",
    "nyc_geo.plot(column='price', cmap='Wistia', legend=True, figsize=(10, 8))\n",
    "plt.title('Average Price by Neighborhood Group')\n",
    "plt.show()"
   ],
   "id": "38ec1e237521016e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "airbnb.describe()",
   "id": "88b3665fdf389bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "id": "a1d67e854817ca7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(airbnb['price'], bins=50, kde=True, color='blue')\n",
    "plt.title('Distribution of Listing Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "id": "ad79bc14aaf9be09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lower_percentile = airbnb['price'].quantile(0.01)  # 1st percentile\n",
    "upper_percentile = airbnb['price'].quantile(0.99)  # 99th percentile\n",
    "\n",
    "airbnb = airbnb[(airbnb['price'] >= lower_percentile) & (airbnb['price'] <= upper_percentile)]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(airbnb['price'], bins=50, kde=True, color='blue')\n",
    "plt.title('Distribution of Listing Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "id": "81d793803b6dfd47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='room_type', y='price', data=airbnb, hue='room_type', showfliers=False)\n",
    "plt.title('Price Distribution by Room Type')\n",
    "plt.xlabel('Room Type')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ],
   "id": "4eb86a2ada10d861",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_histograms(dataframe, columns, bins=50, figsize=(12, 32)):\n",
    "    n_cols = 2\n",
    "    n_rows = -(-len(columns) // n_cols)\n",
    "\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, column in enumerate(columns):\n",
    "        if column in dataframe.columns:\n",
    "            axes[i].hist(dataframe[column].dropna(), bins=bins, color='blue', alpha=0.7, edgecolor='black')\n",
    "            axes[i].set_title(column)\n",
    "            axes[i].set_xlabel('Value')\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, f\"Column '{column}' not found\",\n",
    "                         ha='center', va='center', fontsize=10, color='red')\n",
    "            axes[i].set_axis_off()\n",
    "\n",
    "    \n",
    "    for j in range(len(columns), len(axes)):\n",
    "        axes[j].set_axis_off()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_violin_plots(dataframe, columns, figsize=(12, 32)):\n",
    "    n_cols = 2\n",
    "    n_rows = -(-len(columns) // n_cols)\n",
    "\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, column in enumerate(columns):\n",
    "        sns.violinplot(x=dataframe[column], ax=axes[i])\n",
    "        axes[i].set_title(column)\n",
    "        axes[i].set_xlabel('Value')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    \n",
    "    for j in range(len(columns), len(axes)):\n",
    "        axes[j].set_axis_off()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_box_plots(dataframe, columns, figsize=(12, 32)):\n",
    "    n_cols = 2\n",
    "    n_rows = -(-len(columns) // n_cols)\n",
    "\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, column in enumerate(columns):\n",
    "        sns.boxplot(x=dataframe[column], ax=axes[i])\n",
    "        axes[i].set_title(column)\n",
    "        axes[i].set_xlabel('Value')\n",
    "\n",
    "    \n",
    "    for j in range(len(columns), len(axes)):\n",
    "        axes[j].set_axis_off()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_pie_charts_grid(dataframe, columns, figsize=(12, 8)):\n",
    "    n_cols = 2\n",
    "    n_rows = -(-len(columns) // n_cols)\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, column in enumerate(columns):\n",
    "        if column in dataframe.columns:\n",
    "            if column == 'bedrooms':\n",
    "                data = dataframe[column].apply(lambda x: x if x <= 3 else '4+').value_counts()\n",
    "            elif column == 'bathrooms':\n",
    "                data = dataframe[column].apply(lambda x: x if x <= 2 else '3+').value_counts()\n",
    "            else:\n",
    "                data = dataframe[column].value_counts()\n",
    "\n",
    "            labels = data.index\n",
    "            sizes = data.values\n",
    "\n",
    "            wedges, texts, autotexts = axes[i].pie(\n",
    "                sizes, autopct='%1.1f%%', startangle=90, colors=plt.cm.Paired.colors, labels=None\n",
    "            )\n",
    "\n",
    "            axes[i].legend(wedges, labels, title=column, loc=\"best\", fontsize='small')\n",
    "            axes[i].set_title(f\"Pie Chart of {column}\")\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, f\"Column '{column}' not found\",\n",
    "                         ha='center', va='center', fontsize=10, color='red')\n",
    "            axes[i].set_axis_off()\n",
    "\n",
    "    for j in range(len(columns), len(axes)):\n",
    "        axes[j].set_axis_off()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "columns_to_plot_histogram = ['host_listings_count', 'avg_distance_to_attractions', 'number_of_reviews', 'bathrooms', 'bedrooms', 'beds']\n",
    "\n",
    "columns_to_plot_violin_plots = ['host_since', 'accommodates', 'amenities_count', 'avg_distance_to_attractions']\n",
    "\n",
    "columns_to_plot_box_plots = ['host_response_rate', 'review_scores_rating', 'description_sentiment', 'description_length']\n",
    "\n",
    "plot_histograms(airbnb, columns_to_plot_histogram, figsize=(12, 12))\n",
    "plot_violin_plots(airbnb, columns_to_plot_violin_plots, figsize=(12, 12))\n",
    "plot_box_plots(airbnb, columns_to_plot_box_plots, figsize=(12, 12))\n",
    "\n",
    "columns_to_plot_pie = ['room_type', 'neighbourhood_group_cleansed', 'host_is_superhost', 'host_has_profile_pic']\n",
    "\n",
    "plot_pie_charts_grid(airbnb, columns_to_plot_pie)"
   ],
   "id": "b01d937fa301db9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "airbnb = airbnb.drop(columns = ['host_has_profile_pic', 'host_response_rate', 'host_listings_count'])",
   "id": "f5b11a99fe8d47c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "upper_percentile = airbnb['bathrooms'].quantile(0.99)\n",
    "airbnb = airbnb[airbnb['bathrooms'] <= upper_percentile]\n",
    "\n",
    "upper_percentile = airbnb['beds'].quantile(0.99)\n",
    "airbnb = airbnb[airbnb['beds'] <= upper_percentile]\n",
    "\n",
    "upper_percentile = airbnb['bedrooms'].quantile(0.99)\n",
    "airbnb = airbnb[airbnb['bedrooms'] <= upper_percentile]\n",
    "\n",
    "upper_percentile = airbnb['number_of_reviews'].quantile(0.99)\n",
    "airbnb = airbnb[airbnb['number_of_reviews'] <= upper_percentile]\n",
    "\n",
    "columns_to_plot = ['number_of_reviews', 'bathrooms', 'bedrooms', 'beds']\n",
    "plot_histograms(airbnb, columns_to_plot, figsize=(12, 8))"
   ],
   "id": "52623cdbef347340",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(airbnb.select_dtypes(include=np.number).corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.show()"
   ],
   "id": "147f06bbf15e6f4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "airbnb['log_number_of_reviews'] = np.log(airbnb['number_of_reviews'] + 1)\n",
    "airbnb['log_accommodates'] = np.log(airbnb['accommodates'] + 1)\n",
    "airbnb['squared_review_scores_rating'] = airbnb['review_scores_rating'] ** 2\n",
    "columns_to_plot = ['number_of_reviews', 'log_number_of_reviews', 'accommodates', 'log_accommodates', 'review_scores_rating', 'squared_review_scores_rating']\n",
    "plot_histograms(airbnb, columns_to_plot, figsize=(12, 12))"
   ],
   "id": "150a7f27820a8685",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "corr_matrix = airbnb[['review_scores_rating', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'price']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap: Price and Star Ratings', fontsize=16)\n",
    "plt.show()"
   ],
   "id": "3e10fb86d19ba0cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "airbnb = airbnb.drop(columns = ['review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_rating'])\n",
    "airbnb = airbnb.drop(columns = ['number_of_reviews', 'accommodates'])"
   ],
   "id": "c6eb71564bbce7c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(airbnb.select_dtypes(include=np.number).corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.show()"
   ],
   "id": "3f0f48fb4e410379",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Modelling",
   "id": "f70ae4573dadbb69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ],
   "id": "c3df1b268792fd01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Categorical features encoding\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "X_temp = airbnb.copy()\n",
    "\n",
    "numerical_cols = X_temp.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_cols = X_temp.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "transformed_data = preprocessor.fit_transform(X_temp)\n",
    "\n",
    "cat_feature_names = preprocessor.transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_cols)\n",
    "all_feature_names = numerical_cols + list(cat_feature_names)\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=all_feature_names)\n",
    "\n",
    "print(f\"Number of columns after encoding and scaling: {len(transformed_df.columns)}\")\n",
    "print(transformed_df.columns)\n",
    "transformed_df"
   ],
   "id": "90810aee3c83a69f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(transformed_df.corr(), annot=False, fmt=\".2f\", cmap='viridis')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "102f76e99906617b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split the data\n",
    "X = transformed_df.drop(['price'], axis=1)\n",
    "y = transformed_df['price']\n",
    "# y = airbnb['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "id": "95d16372c5ac1eb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select most important features\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "feature_selector = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "feature_selector.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = feature_selector.predict(X_test)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f}\")\n",
    "print(f\"R^2 Score: {r2_score(y_test, y_pred_test):.2f}\")\n",
    "\n",
    "feature_importances = feature_selector.feature_importances_\n",
    "important_features = np.argsort(feature_importances)[-15:]\n",
    "X_train_selected = X_train.iloc[:, important_features]\n",
    "X_test_selected = X_test.iloc[:, important_features]\n",
    "\n",
    "print(\"Selected important features:\")\n",
    "print(X_train.columns[important_features])"
   ],
   "id": "18ade45f3176dc0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train_selected",
   "id": "1621e6d02bd107c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train_selected, y_train)\n",
    "\n",
    "coefficients = linear_reg.coef_\n",
    "\n",
    "coef_df = pd.DataFrame({'Feature': X_train_selected.columns, 'Coefficient': coefficients})\n",
    "\n",
    "print(\"\\nCoefficients for Selected Features:\")\n",
    "print(coef_df)\n",
    "\n",
    "y_pred_train = linear_reg.predict(X_train_selected)\n",
    "y_pred_test = linear_reg.predict(X_test_selected)\n",
    "\n",
    "print(\"Training Set Metrics:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_train, y_pred_train)):.2f}\")\n",
    "print(f\"R^2 Score: {r2_score(y_train, y_pred_train):.2f}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f}\")\n",
    "print(f\"R^2 Score: {r2_score(y_test, y_pred_test):.2f}\")"
   ],
   "id": "c27adbe12a19145d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "random_forest = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [600],\n",
    "    'max_depth': [15],\n",
    "    # 'min_samples_split': [5, 10],\n",
    "    # 'min_samples_leaf': [4, 6, 8],\n",
    "    # 'max_features': ['auto', 0.5, 0.8]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=random_forest,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True,\n",
    "                           cv=3,\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "###################################################################\n",
    "cv_results = grid_search.cv_results_\n",
    "best_index = grid_search.best_index_\n",
    "best_train_score = -cv_results['mean_train_score'][best_index]\n",
    "best_test_score = -cv_results['mean_test_score'][best_index]\n",
    "best_test_std = cv_results['std_test_score'][best_index]\n",
    "\n",
    "print(\"\\nTraining Set Metrics (CV Results for Best Parameters):\")\n",
    "print(f\"Mean Train MSE: {best_train_score:.4f}\")\n",
    "print(f\"Mean CV Test MSE: {best_test_score:.4f} ± {best_test_std:.4f}\")\n",
    "###################################################################\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "y_pred_train = best_rf.predict(X_train_selected)\n",
    "y_pred_test = best_rf.predict(X_test_selected)\n",
    "\n",
    "# print(\"Cross-Validation Metrics (Training Set):\")\n",
    "# print(f\"Mean CV MSE: {-np.mean(cv_mse_scores):.2f} ± {np.std(cv_mse_scores):.2f}\")\n",
    "# print(f\"Mean CV R^2: {np.mean(cv_r2_scores):.2f} ± {np.std(cv_r2_scores):.2f}\")\n",
    "\n",
    "print(\"\\nTraining Set Metrics:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_train, y_pred_train)):.2f}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_train, y_pred_train):.2f}\")\n",
    "print(f\"R^2 Score: {r2_score(y_train, y_pred_train):.2f}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred_test):.2f}\")\n",
    "print(f\"R^2 Score: {r2_score(y_test, y_pred_test):.2f}\")"
   ],
   "id": "eb1763bbb42855c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "xgb_regressor = XGBRegressor(objective='reg:squarederror', random_state=42, verbosity=1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [800],\n",
    "    'max_depth': [15],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'gamma': [1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_regressor,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True,\n",
    "                           cv=3,\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "###################################################################\n",
    "cv_results = grid_search.cv_results_\n",
    "best_index = grid_search.best_index_\n",
    "best_train_score = -cv_results['mean_train_score'][best_index]\n",
    "best_test_score = -cv_results['mean_test_score'][best_index]\n",
    "best_test_std = cv_results['std_test_score'][best_index]\n",
    "\n",
    "print(\"\\nTraining Set Metrics (CV Results for Best Parameters):\")\n",
    "print(f\"Mean Train MSE: {best_train_score:.4f}\")\n",
    "print(f\"Mean CV Test MSE: {best_test_score:.4f} ± {best_test_std:.4f}\")\n",
    "###################################################################\n",
    "\n",
    "best_xgb = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "y_pred_train = best_xgb.predict(X_train_selected)\n",
    "y_pred_test = best_xgb.predict(X_test_selected)\n",
    "\n",
    "# scaler = preprocessor.transformers_[0][1]\n",
    "# y_pred_real = scaler.inverse_transform(\n",
    "#     np.concatenate([X_test_selected, y_pred_test.reshape(-1, 1)], axis=1)\n",
    "# )[:, -1]\n",
    "# y_real = scaler.inverse_transform(\n",
    "#     np.concatenate([X_test_selected, y_test.reshape(-1, 1)], axis=1)\n",
    "# )[:, -1]\n",
    "# \n",
    "# # Step 5: Calculate error metrics in the original scale\n",
    "# mae_real = mean_absolute_error(y_real, y_pred_real)\n",
    "# mse_real = mean_squared_error(y_real, y_pred_real)\n",
    "# r2_real = r2_score(y_real, y_pred_real)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nTraining Set Metrics:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_train, y_pred_train)):.2f}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_train, y_pred_train):.2f}\")\n",
    "print(f\"R^2 Score: {r2_score(y_train, y_pred_train):.2f}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred_test):.2f}\")\n",
    "print(f\"R^2 Score: {r2_score(y_test, y_pred_test):.2f}\")\n",
    "\n",
    "# print(\"\\nTest Set Metrics scaled back:\")\n",
    "# print(f\"Mean Squared Error (MSE): {mse_real:.2f}\")\n",
    "# print(f\"Mean Absolute Error (MAE): {mae_real: .2f}\")\n",
    "# print(f\"R^2 Score: {r2_real:.2f}\")"
   ],
   "id": "52dc42a6b99d54f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "mlp_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(256, 128, 64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.03,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=800,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('mlp', mlp_model),\n",
    "        ('xgb', xgb_model)\n",
    "    ],\n",
    "    final_estimator=Ridge(alpha=3.0)\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "# kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "# cv_scores = cross_val_score(stacking_model, X_train_selected, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "# \n",
    "# print(f\"Cross-Validation Mean Squared Error: {-cv_scores.mean():.2f} ± {cv_scores.std():.2f}\")\n",
    "\n",
    "stacking_reg.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred_train = stacking_reg.predict(X_train_selected)\n",
    "y_pred_test = stacking_reg.predict(X_test_selected)\n",
    "\n",
    "print(\"Training Set Metrics:\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_train)):.2f}, R^2: {r2_score(y_train, y_pred_train):.2f}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f}, R^2: {r2_score(y_test, y_pred_test):.2f}\")"
   ],
   "id": "c0ea55ab04082e59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(256, 128, 64, 64, 32, 16), (256, 256, 256)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'alpha': [0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_mlp = GridSearchCV(MLPRegressor(max_iter=4000, random_state=42), param_grid_mlp, cv=3, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_mlp.fit(X_train_selected, y_train)\n",
    "\n",
    "###################################################################\n",
    "cv_results = grid_mlp.cv_results_\n",
    "best_index = grid_mlp.best_index_\n",
    "best_train_score = -cv_results['mean_train_score'][best_index]\n",
    "best_test_score = -cv_results['mean_test_score'][best_index]\n",
    "best_test_std = cv_results['std_test_score'][best_index]\n",
    "\n",
    "print(\"\\nCV Results for Best Parameters:\")\n",
    "print(f\"Mean Train MSE: {best_train_score:.4f}\")\n",
    "print(f\"Mean CV Test MSE: {best_test_score:.4f} ± {best_test_std:.4f}\")\n",
    "###################################################################\n",
    "best_mlp = grid_mlp.best_estimator_\n",
    "\n",
    "y_pred_train = best_mlp.predict(X_train_selected)\n",
    "y_pred_test = best_mlp.predict(X_test_selected)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Metrics:\")\n",
    "print(f\"MSE: {mse_train:.2f}, R^2: {r2_train:.2f}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"MSE: {mse_test:.2f}, R^2: {r2_test:.2f}\")\n",
    "\n",
    "print(f\"Best parameters: {grid_mlp.best_params_}\")"
   ],
   "id": "89f3fb6f702e53fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_svr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'epsilon': [0.001, 0.01, 0.1, 1, 5],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'degree': [2, 3, 4]\n",
    "}\n",
    "grid_svr = GridSearchCV(SVR(), param_grid_svr, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_svr.fit(X_train_selected, y_train)\n",
    "\n",
    "best_svr = grid_svr.best_estimator_\n",
    "print(f\"Best Parameters: {grid_svr.best_params_}\")\n",
    "\n",
    "y_pred_train = best_svr.predict(X_train_selected)\n",
    "y_pred_test = best_svr.predict(X_test_selected)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Set Metrics:\")\n",
    "print(f\"MSE: {mse_train:.2f}, R^2: {r2_train:.2f}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"MSE: {mse_test:.2f}, R^2: {r2_test:.2f}\")\n",
    "\n",
    "print(f\"Best parameters: {grid_svr.best_params_}\")"
   ],
   "id": "ed9ee0294c18533d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_linear_regression_rmse = 93.18\n",
    "best_linear_r2 = 0.34\n",
    "\n",
    "best_random_forest_rmse = 41.12\n",
    "best_random_forest_r2 = 0.71\n",
    "\n",
    "best_xgb_rmse = 48.32\n",
    "best_xgb_r2 = 0.69\n",
    "\n",
    "best_stacking_rmse = 29.77\n",
    "best_stacking_r2 = 0.79\n",
    "\n",
    "best_mlp_rmse = 51.37\n",
    "best_mlp_r2 = 0.61\n",
    "\n",
    "best_svr_rmse = 54.81\n",
    "best_svr_r2 = 0.61\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'Method': ['Linear Regression', 'Random Forest', 'XGBoost', 'Stacking (XGB + RF)', 'MLP', 'SVR'],\n",
    "    'RMSE': [best_linear_regression_rmse, best_random_forest_rmse, best_xgb_rmse, best_stacking_rmse, best_mlp_rmse, best_svr_rmse],\n",
    "    'R2': [best_linear_r2, best_random_forest_r2, best_xgb_r2, best_stacking_r2, best_mlp_r2, best_svr_r2]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "bar_width = 0.4\n",
    "x = np.arange(len(df['Method']))\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "bars_rmse = ax1.bar(x - bar_width/2, df['RMSE'], width=bar_width, label='RMSE', color='blue', alpha=0.7)\n",
    "ax1.set_ylabel('RMSE', fontsize=12, color='blue')\n",
    "ax1.set_xlabel('Model', fontsize=12)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(df['Method'], rotation=45, ha='right')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "bars_r2 = ax2.bar(x + bar_width/2, df['R2'], width=bar_width, label='R2', color='green', alpha=0.7)\n",
    "ax2.set_ylabel('R2', fontsize=12, color='green')\n",
    "ax2.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "fig.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.1), ncol=2, fontsize=12)\n",
    "plt.title('RMSE and R2 Comparison for Different Models', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "b25d15c56582c620",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d82161ff9e2b234d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
